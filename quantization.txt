~ Quantization 코드기준 접근 방향 ~

pytorch ==> pytorch 2.0 기준의 document 보고 해도 되겠지만 tutorial 제외 자료가 너무~~~ 적음

pytorch_quantization ==> NVIDIA 어빠들이 만들어놨는디 tutorial 자료 따라서 하다보면 bias 부분 자료형 문제땜시 에러남( dynamic quantization이라서 그럼 시발)

ONNX ==> int8 기준으로만 quantization만 해주지만 생각보다 자료도 많고 공부하기 좋음

TESSORT ==> FP16도 된다함 자료도 꽤 있음

<ONNX 기준 Post Training Quantization 진행>
1. pretrained model을 onnx 형태로 변환

2. preprocess 진행 (ex. python -m onnxruntime.quantization.preprocess --input test.onnx --output preprocess_test.onnx)

3. preprocess로 저정한 onnx 파일을 가지고 quantization 진행
   CNN은 static quantization으로 진행해야함
   CNN을 제외한 다른 것은 dynamic quantization으로 진행해야함 
   CNN과 다른 연산이 혼재된 경우에는 아래와 같이 dynamic으로 Conv 연산이 매우 작을경우에는 아래와 같이 Conv 연산만 제외하고 선언해서 사용가능
     quantize_dynamic('preprocess_test.onnx', 'test_quantized.onnx', weight_type=QuantType.QInt8,op_types_to_quantize=['MatMul', 'Attention', 'LSTM', 'Gather', 'Transpose', 'EmbedLayerNormalization'] )
   CNN이 포함되어야 하면 static 진행해야하며 이때는 CalibrationDataReader가 필요하게됨 ( static 이랑 dynamic 차이 보고 확인해야할듯? )
   static quantization ==> 주로 CNN에서 사용됨